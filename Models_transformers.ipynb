{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjSS2ckV9ziJtLOY+dL0JL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabincool20/colab_glaucoma/blob/main/Models_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myCbLPyTdzo7",
        "outputId": "847c1fb0-38f7-481a-832c-fb89b820d837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import resnet18\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "# ====== Paths to your saved models ======\n",
        "MODEL_PATHS = {\n",
        "    \"resnet_fundus_acrima\": \"/content/drive/MyDrive/trained_models_all/trained_resnet_models/acrima_resnet18.pth\",\n",
        "    \"resnet_fundus_origa\": \"/content/drive/MyDrive/trained_models_all/trained_resnet_models/origa_resnet18.pth\",\n",
        "    \"resnet_fundus_rimone\": \"/content/drive/MyDrive/trained_models_all/trained_resnet_models/rimone_resnet18.pth\",\n",
        "    \"vit_fundus_acrima\": \"/content/drive/MyDrive/trained_models_all/trained_vit_models/acrima_label_vit.pth\",\n",
        "    \"vit_fundus_origa\": \"/content/drive/MyDrive/trained_models_all/trained_vit_models/origa_label_vit.pth\",\n",
        "    \"vit_fundus_rimone\": \"/content/drive/MyDrive/trained_models_all/trained_vit_models/rimone_label_vit.pth\",\n",
        "    \"resnet_oct\": \"/content/drive/MyDrive/trained_models_all/resnet_oct.pth\",\n",
        "    \"vit_oct\": \"/content/drive/MyDrive/trained_models_all/vit_oct.pth\",\n",
        "}\n",
        "\n",
        "# ====== Load ResNet18 model function ======\n",
        "def load_resnet_model(path, model_key):\n",
        "    model = resnet18(pretrained=False)\n",
        "\n",
        "    if \"origa\" in model_key:\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(model.fc.in_features, 2)\n",
        "        )\n",
        "    elif \"rimone\" in model_key:\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(model.fc.in_features, 2)\n",
        "        )\n",
        "    elif \"acrima\" in model_key:\n",
        "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    else:\n",
        "        model.fc = nn.Linear(model.fc.in_features, 2)  # default fallback\n",
        "\n",
        "    model.load_state_dict(torch.load(path, map_location=torch.device(\"cpu\")))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# ====== Load ViT model function ======\n",
        "\n",
        "\n",
        "def load_vit_model(path):\n",
        "    model = timm.create_model(\"vit_base_patch16_224\", pretrained=False, num_classes=2)\n",
        "    model.load_state_dict(torch.load(path, map_location=torch.device(\"cpu\")))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# ====== Image transforms ======\n",
        "resnet_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])\n",
        "\n",
        "vit_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "vit_processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "\n",
        "# ====== Prediction function for each model type ======\n",
        "def predict_resnet(image, model):\n",
        "    image_tensor = resnet_transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "    return \"Glaucoma\" if pred == 0 else \"Non_Glaucoma\"\n",
        "\n",
        "def predict_vit(image, model):\n",
        "    image_tensor = vit_transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "    return \"Glaucoma\" if pred == 0 else \"Non_Glaucoma\"\n",
        "\n",
        "# ====== Unified prediction wrapper ======\n",
        "MODELS = {\n",
        "    key: load_resnet_model(path, key) if 'resnet' in key else load_vit_model(path)\n",
        "    for key, path in MODEL_PATHS.items()\n",
        "}\n",
        "\n",
        "PREDICTORS = {\n",
        "    key: predict_resnet if 'resnet' in key else predict_vit\n",
        "    for key in MODELS\n",
        "}\n",
        "\n",
        "# ====== Function to process a folder of images with all models ======\n",
        "def process_all_models(folder_path):\n",
        "    results = []\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    image = Image.open(file_path).convert(\"RGB\")\n",
        "                    row = {\"filename\": os.path.relpath(file_path, folder_path)}\n",
        "                    for model_name, model in MODELS.items():\n",
        "                        predictor = PREDICTORS[model_name]\n",
        "                        row[model_name] = predictor(image, model)\n",
        "                    results.append(row)\n",
        "                except Exception as e:\n",
        "                    results.append({\"filename\": file_path, \"error\": str(e)})\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    output_excel = os.path.join(folder_path, \"combined_model_predictions.xlsx\")\n",
        "    df.to_excel(output_excel, index=False)\n",
        "    return output_excel\n",
        "\n",
        "# ====== Gradio Interface ======\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üß† Unified Glaucoma Detection Tool\")\n",
        "\n",
        "    with gr.Tab(\"1Ô∏è‚É£ Upload Single/Multiple Images\"):\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"Upload Image(s)\", file_types=[\".jpg\", \".png\", \".jpeg\"], file_count=\"multiple\")\n",
        "            model_choice_1 = gr.Dropdown(choices=list(MODELS.keys()), label=\"Select Model\")\n",
        "        output_text_1 = gr.Textbox(label=\"Predictions\")\n",
        "\n",
        "        def predict_uploaded_images(files, model_key):\n",
        "            if not files:\n",
        "                return \"No images uploaded.\"\n",
        "            model = MODELS[model_key]\n",
        "            predictor = PREDICTORS[model_key]\n",
        "            results = []\n",
        "            for file in files:\n",
        "                try:\n",
        "                    image = Image.open(file.name).convert(\"RGB\")\n",
        "                    pred = predictor(image, model)\n",
        "                    results.append(f\"{os.path.basename(file.name)} ‚Üí {pred}\")\n",
        "                except Exception as e:\n",
        "                    results.append(f\"{os.path.basename(file.name)} ‚Üí Error: {str(e)}\")\n",
        "            return \"\\n\".join(results)\n",
        "\n",
        "        predict_btn_1 = gr.Button(\"Run Prediction\")\n",
        "        predict_btn_1.click(predict_uploaded_images, inputs=[file_input, model_choice_1], outputs=output_text_1)\n",
        "\n",
        "    with gr.Tab(\"2Ô∏è‚É£ Upload Folder\"):\n",
        "        folder_input = gr.File(label=\"Upload Folder (ZIP)\", file_types=[\".zip\"])\n",
        "        model_choice_2 = gr.Dropdown(choices=list(MODELS.keys()), label=\"Select Model\")\n",
        "        folder_output = gr.File(label=\"Excel Output\")\n",
        "\n",
        "        def process_uploaded_zip(zip_file, model_key):\n",
        "            import zipfile\n",
        "            import tempfile\n",
        "\n",
        "            extract_dir = tempfile.mkdtemp()\n",
        "            with zipfile.ZipFile(zip_file.name, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "\n",
        "            model = MODELS[model_key]\n",
        "            predictor = PREDICTORS[model_key]\n",
        "\n",
        "            results = []\n",
        "            for root, _, files in os.walk(extract_dir):\n",
        "                for file in files:\n",
        "                    if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                        file_path = os.path.join(root, file)\n",
        "                        try:\n",
        "                            image = Image.open(file_path).convert(\"RGB\")\n",
        "                            pred = predictor(image, model)\n",
        "                            results.append({\"filename\": os.path.relpath(file_path, extract_dir), \"prediction\": pred})\n",
        "                        except Exception as e:\n",
        "                            results.append({\"filename\": file, \"error\": str(e)})\n",
        "\n",
        "            df = pd.DataFrame(results)\n",
        "            output_excel = os.path.join(extract_dir, \"predictions_from_folder.zip.xlsx\")\n",
        "            df.to_excel(output_excel, index=False)\n",
        "            return output_excel\n",
        "\n",
        "        predict_btn_2 = gr.Button(\"Run Prediction on Folder\")\n",
        "        predict_btn_2.click(process_uploaded_zip, inputs=[folder_input, model_choice_2], outputs=folder_output)\n",
        "\n",
        "    with gr.Tab(\"3Ô∏è‚É£ Enter Folder Path (Google Drive/Colab)\"):\n",
        "        path_input = gr.Textbox(label=\"Enter Folder Path\", placeholder=\"/content/drive/MyDrive/OCT_Split/test\")\n",
        "        model_choice_3 = gr.Dropdown(choices=list(MODELS.keys()), label=\"Select Model\")\n",
        "        path_output = gr.File(label=\"Excel Output\")\n",
        "\n",
        "        def process_by_path(folder_path, model_key):\n",
        "            model = MODELS[model_key]\n",
        "            predictor = PREDICTORS[model_key]\n",
        "            results = []\n",
        "            for root, _, files in os.walk(folder_path):\n",
        "                for file in files:\n",
        "                    if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                        file_path = os.path.join(root, file)\n",
        "                        try:\n",
        "                            image = Image.open(file_path).convert(\"RGB\")\n",
        "                            pred = predictor(image, model)\n",
        "                            results.append({\"filename\": os.path.relpath(file_path, folder_path), \"prediction\": pred})\n",
        "                        except Exception as e:\n",
        "                            results.append({\"filename\": file, \"error\": str(e)})\n",
        "            df = pd.DataFrame(results)\n",
        "            output_excel = os.path.join(folder_path, \"model_predictions_from_path.xlsx\")\n",
        "            df.to_excel(output_excel, index=False)\n",
        "            return output_excel\n",
        "\n",
        "        predict_btn_3 = gr.Button(\"Run Prediction on Path\")\n",
        "        predict_btn_3.click(process_by_path, inputs=[path_input, model_choice_3], outputs=path_output)\n",
        "\n",
        "demo.launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "swiNT6EqeIwM",
        "outputId": "f8100117-3b00-405f-a114-62161158a165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://337b2fcd760223f716.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://337b2fcd760223f716.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}